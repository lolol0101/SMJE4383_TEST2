# -*- coding: utf-8 -*-
"""TEST2Q1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19gWVx6n3fI_wVF-F6ETSSxNJtg4DwLEz
"""

pip install pandas openai

import pandas as pd
import openai
import io
from google.colab import files  # Import files from google.colab

# Set your OpenAI API key
openai.api_key = 'Testing'

class ExcelReader:
    def __init__(self, file_content):
        self.file_content = file_content

    def read_excel(self, header=1):  # Change header to 1 to read headers from the second row
        """
        Reads the Excel file into a DataFrame using pandas.
        """
        self.data = pd.read_excel(io.BytesIO(self.file_content), header=header)
        return self.data

class DataProcessor:
    def __init__(self, data):
        self.data = data

    def process_data(self, salary_column, department_column):
        """
        Processes the data to calculate basic statistics.
        """
        if self.data is not None:
            summary = {
                "average_salary": self.data[salary_column].mean(),
                "department_distribution": self.data[department_column].value_counts().to_dict()
            }
            return summary
        else:
            return {"error": "Data not loaded. Please read the Excel file first."}

class GPTSummarizer:
    def __init__(self, data):
        self.data = data

    def summarize_with_gpt(self):
        """
        Generates a natural language summary of the data using OpenAI's GPT.
        """
        if self.data is not None:
            # Convert the DataFrame to a string for GPT processing
            data_str = self.data.to_string()

            # Use OpenAI GPT to generate a summary
            client = openai.OpenAI()  # Initialize the OpenAI client
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",  # Use the GPT-3.5 Turbo model
                messages=[
                    {"role": "system", "content": "You are a helpful assistant."},
                    {"role": "user", "content": f"Summarize the following data:\n{data_str}"}
                ],
                max_tokens=150
            )

            return response.choices[0].message.content.strip()
        else:
            return "Data not loaded. Please read the Excel file first."

# Example usage
uploaded = files.upload()  # Prompt the user to upload the file

# Get the filename and file content from the uploaded dictionary
filename = list(uploaded.keys())[0]
file_content = uploaded[filename]

# Read the Excel file using BytesIO to handle the file content
excel_reader = ExcelReader(file_content)
data = excel_reader.read_excel(header=1)  # Set header=1 to read headers from the second row

# Print the column names to verify
print("Columns in the Excel file:", data.columns)

# Process the data
data_processor = DataProcessor(data)

# Get the actual column names from the DataFrame
try:
    actual_salary_column = data.columns[data.columns.str.contains("Salary", case=False, na=False)].values[0]
except IndexError:
    print("Error: No column containing 'Salary' found. Please check your Excel file.")
    exit()

try:
    actual_department_column = data.columns[data.columns.str.contains("Department", case=False, na=False)].values[0]
except IndexError:
    print("Error: No column containing 'Department' found. Please check your Excel file.")
    exit()

# Process the data using the actual column names
processed_data = data_processor.process_data(actual_salary_column, actual_department_column)
print("Processed Data:", processed_data)

# Summarize with GPT
gpt_summarizer = GPTSummarizer(data)
summary = gpt_summarizer.summarize_with_gpt()
print("GPT Summary:", summary)